###############################################################################
# streamlit_app.py  (2025-04-29 ç‰ˆ)
###############################################################################
import os, sys, traceback, warnings
import streamlit as st
import snowflake.connector as sf
import pandas as pd, numpy as np
import matplotlib.pyplot as plt, seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. ê¸°ë³¸ í™˜ê²½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
os.environ["STREAMLIT_SERVER_HEALTH_CHECK_ENABLED"] = "false"
st.set_page_config(page_title="ì„œìš¸ì‹œ ê°ì„± ì§€ìˆ˜ ëŒ€ì‹œë³´ë“œ", layout="wide")
sns.set_style("whitegrid")

import matplotlib
if sys.platform.startswith("win"):
    matplotlib.rcParams["font.family"] = "Malgun Gothic"
else:
    matplotlib.rcParams["font.family"] = "AppleGothic"
matplotlib.rcParams["axes.unicode_minus"] = False
st.markdown('<style>*{font-family:"Malgun Gothic",sans-serif!important;}</style>',
            unsafe_allow_html=True)

st.write("ğŸš€ **Streamlit ì•± ì‹œì‘!**")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. Snowflake ì—°ê²° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner=False)
def make_conn():
    try:
        s = st.secrets["snowflake"]
        conn = sf.connect(
            user      = s["user"],
            password  = s["password"],
            account   = s["account"],           # ì˜ˆ: "TGLBRLT-EKB57194"
            warehouse = "COMPUTE_WH",
            ocsp_fail_open = True,
            insecure_mode  = True,
            session_parameters = {"QUERY_TAG":"feel_idx_dashboard"}
        )
        return conn
    except Exception as e:
        st.error(f"âŒ Snowflake ì—°ê²° ì‹¤íŒ¨: {e}")
        st.stop()

def run_query(q:str) -> pd.DataFrame:
    with make_conn() as conn:
        cur = conn.cursor()
        cur.execute(q)
        df  = pd.DataFrame(cur.fetchall(), columns=[c[0] for c in cur.description])
        cur.close()
    return df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. ë°ì´í„° ì „ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE = "SEOUL_DISTRICTLEVEL_DATA_FLOATING_POPULATION_CONSUMPTION_AND_ASSETS.GRANDATA"
Q_FP, Q_CARD, Q_ASSET, Q_SCCO = (
    f"SELECT * FROM {BASE}.FLOATING_POPULATION_INFO",
    f"SELECT * FROM {BASE}.CARD_SALES_INFO",
    f"SELECT * FROM {BASE}.ASSET_INCOME_INFO",
    f"SELECT * FROM {BASE}.M_SCCO_MST",
)

@st.cache_data(show_spinner=True)
def load_and_prep(sample_frac:float=0.01) -> pd.DataFrame:

    # ---- â‘  ë¡œë“œ (ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨) ----
    try:
        fp, card, asset, scco = (run_query(Q_FP),
                                 run_query(Q_CARD),
                                 run_query(Q_ASSET),
                                 run_query(Q_SCCO))
    except Exception as e:
        st.error(f"ì¿¼ë¦¬ ì‹¤íŒ¨: {e}")
        st.stop()

    # ---- â‘¡ 1 % ìƒ˜í”Œë§ ----
    fp = fp.sample(frac=sample_frac, random_state=42)

    # ---- â‘¢ ë¨¸ì§€ ----
    fp_card = pd.merge(fp, card, how="inner",
                       on=["STANDARD_YEAR_MONTH","DISTRICT_CODE","AGE_GROUP","GENDER",
                           "TIME_SLOT","WEEKDAY_WEEKEND"])
    data = pd.merge(fp_card, asset, how="inner",
                    on=["STANDARD_YEAR_MONTH","DISTRICT_CODE","AGE_GROUP","GENDER"])

    # ---- â‘£ í–‰ì •ë™ í•œê¸€ëª… ----
    scco_map = (scco.drop_duplicates("DISTRICT_CODE")
                     .set_index("DISTRICT_CODE")["DISTRICT_KOR_NAME"].to_dict())
    data["DISTRICT_KOR_NAME"] = data["DISTRICT_CODE"].map(scco_map)

    # ---- â‘¤ íŒŒìƒ ë³€ìˆ˜ ----
    data["ì „ì²´ì¸êµ¬"]     = data[["RESIDENTIAL_POPULATION","WORKING_POPULATION",
                                 "VISITING_POPULATION"]].sum(axis=1)
    sale_cols = ["FOOD_SALES","COFFEE_SALES","BEAUTY_SALES",
                 "ENTERTAINMENT_SALES","SPORTS_CULTURE_LEISURE_SALES",
                 "TRAVEL_SALES","CLOTHING_ACCESSORIES_SALES"]
    data["ì—”í„°ì „ì²´ë§¤ì¶œ"] = data[sale_cols].sum(axis=1)
    data["ì†Œë¹„í™œë ¥ì§€ìˆ˜"] = data["ì—”í„°ì „ì²´ë§¤ì¶œ"] / data["ì „ì²´ì¸êµ¬"].replace(0,np.nan)
    data["ìœ ì…ì§€ìˆ˜"]     = data["VISITING_POPULATION"] / (
                            data["RESIDENTIAL_POPULATION"]+data["WORKING_POPULATION"]
                           ).replace(0,np.nan)
    data["ì—”í„°ë§¤ì¶œë¹„ìœ¨"] = data["ì—”í„°ì „ì²´ë§¤ì¶œ"] / data["TOTAL_SALES"].replace(0,np.nan)

    cnt_cols = ["FOOD_COUNT","COFFEE_COUNT","BEAUTY_COUNT",
                "ENTERTAINMENT_COUNT","SPORTS_CULTURE_LEISURE_COUNT",
                "TRAVEL_COUNT","CLOTHING_ACCESSORIES_COUNT"]
    data["ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"] = data[cnt_cols].sum(axis=1)
    data["ì—”í„°ë°©ë¬¸ìë¹„ìœ¨"] = data["ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"] / data["TOTAL_COUNT"].replace(0,np.nan)
    data["ì—”í„°í™œë™ë°€ë„"]   = data["ì—”í„°ì „ì²´ë§¤ì¶œ"] / data["ì „ì²´ì¸êµ¬"].replace(0,np.nan)
    data["ì—”í„°ë§¤ì¶œë°€ë„"]   = data["ì—”í„°ì „ì²´ë§¤ì¶œ"] / data["ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"].replace(0,np.nan)

    # ---- â‘¥ FEEL_IDX (PCA-1) ----
    emo_vars = ["ì—”í„°ì „ì²´ë§¤ì¶œ","ìœ ì…ì§€ìˆ˜","ì—”í„°ë§¤ì¶œë¹„ìœ¨",
                "ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜","ì—”í„°ë°©ë¬¸ìë¹„ìœ¨","ì—”í„°í™œë™ë°€ë„","ì—”í„°ë§¤ì¶œë°€ë„"]
    data["FEEL_IDX"] = np.nan
    X = data[emo_vars].apply(pd.to_numeric, errors="coerce").dropna()
    if not X.empty:
        try:
            pc1 = PCA(n_components=1).fit_transform(StandardScaler().fit_transform(X)).ravel()
            pc1_n = (pc1-pc1.min())/(pc1.max()-pc1.min()+1e-9)
            data.loc[X.index,"FEEL_IDX"] = pc1_n.astype(float)
        except Exception as e:
            warnings.warn(f"PCA ì‹¤íŒ¨: {e}")

    return data

df = load_and_prep()

st.title("ì„œìš¸ì‹œ ì¸ìŠ¤íƒ€ ê°ì„± ì§€ìˆ˜ ë¶„ì„")

if df.empty:
    st.error("âš ï¸ ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. í•„í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("í•„í„°")
    sel_dist = st.multiselect("í–‰ì •ë™", sorted(df["DISTRICT_KOR_NAME"].dropna().unique()))
    sel_age  = st.multiselect("ì—°ë ¹ëŒ€",  sorted(df["AGE_GROUP"].unique()))
    sel_gen  = st.multiselect("ì„±ë³„",     ["M","F"])

mask = (
    (df["DISTRICT_KOR_NAME"].isin(sel_dist) if sel_dist else True) &
    (df["AGE_GROUP"].isin(sel_age)          if sel_age  else True) &
    (df["GENDER"].isin(sel_gen)             if sel_gen  else True)
)
view = df.loc[mask]

if view.empty:
    st.info("ğŸ›ˆ ì„ íƒ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. ìš”ì•½ ì¹´ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def safe_mean(series):
    val = series.mean()
    return "N/A" if pd.isna(val) else f"{val:,.3f}"

c1,c2,c3 = st.columns(3)
c1.metric("í‰ê·  FEEL_IDX",     safe_mean(view["FEEL_IDX"]))
c2.metric("í‰ê·  ì†Œë¹„í™œë ¥ì§€ìˆ˜", safe_mean(view["ì†Œë¹„í™œë ¥ì§€ìˆ˜"]))
c3.metric("í‰ê·  ìœ ì…ì§€ìˆ˜",     safe_mean(view["ìœ ì…ì§€ìˆ˜"]))

tab1,tab2,tab3 = st.tabs(["ì§€ìˆ˜ ìƒìœ„ ì§€ì—­","ì„±ë³„Â·ì—°ë ¹ ë¶„ì„","ì‚°ì ë„"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ íƒ­ 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab1:
    top20 = (view.groupby("DISTRICT_KOR_NAME")["ì†Œë¹„í™œë ¥ì§€ìˆ˜"]
                  .mean().nlargest(20))
    if top20.empty:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        fig, ax = plt.subplots(figsize=(10,4))
        sns.barplot(x=top20.index, y=top20.values, palette="rocket", ax=ax)
        ax.set_xlabel("í–‰ì •ë™"); ax.set_ylabel("ì†Œë¹„í™œë ¥ì§€ìˆ˜")
        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha="right")
        st.pyplot(fig)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ íƒ­ 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab2:
    grp = (view.groupby(["AGE_GROUP","GENDER"])["TOTAL_SALES"]
                .mean().reset_index())
    if grp.empty:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        fig, ax = plt.subplots(figsize=(8,4))
        sns.barplot(data=grp, x="AGE_GROUP", y="TOTAL_SALES",
                    hue="GENDER", palette={"M":"#3498db","F":"#e75480"}, ax=ax)
        ax.set_ylabel("í‰ê·  ë§¤ì¶œ")
        st.pyplot(fig)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ íƒ­ 3 â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab3:
    base = view.dropna(subset=["FEEL_IDX"])
    if base.empty:
        st.info("FEEL_IDX ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        X_CHOICES = ["ì—”í„°ì „ì²´ë§¤ì¶œ","ì†Œë¹„í™œë ¥ì§€ìˆ˜","ìœ ì…ì§€ìˆ˜","ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"]
        Y_CHOICES = ["FEEL_IDX","ì—”í„°í™œë™ë°€ë„","ì—”í„°ë§¤ì¶œë¹„ìœ¨"]
        xx = st.selectbox("X ë³€ìˆ˜", X_CHOICES, key="xx")
        yy = st.selectbox("Y ë³€ìˆ˜", Y_CHOICES, key="yy")
        fig, ax = plt.subplots(figsize=(6,4))
        try:
            sns.scatterplot(data=base, x=xx, y=yy,
                            hue="FEEL_IDX", palette="viridis", alpha=0.4, ax=ax)
        except ValueError as e:
            st.warning(f"í”Œë¡¯ ì˜¤ë¥˜: {e}")
        st.pyplot(fig)

st.divider()
st.caption("ë°ì´í„° ì¶œì²˜ Â· Snowflake Marketplace")
