import os, streamlit as st, snowflake.connector as sf
import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# â”€â”€ ê¸°ë³¸ UI ì„¸íŒ… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
os.environ["STREAMLIT_SERVER_HEALTH_CHECK_ENABLED"] = "false"      # 90-ì´ˆ í—¬ìŠ¤ì²´í¬ ì™„í™”
st.set_page_config(page_title="ì„œìš¸ì‹œ ê°ì„± ì§€ìˆ˜ ëŒ€ì‹œë³´ë“œ", layout="wide")
sns.set_style("whitegrid")
plt.rcParams["font.family"] = "Malgun Gothic"; plt.rcParams["axes.unicode_minus"] = False
st.markdown('<style>*{font-family:"Malgun Gothic",sans-serif!important;}</style>', unsafe_allow_html=True)
st.write("ğŸš€ Streamlit ì•± ì‹œì‘!")

# â”€â”€ Snowflake ì—°ê²° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner=False)
def get_conn():
    s = st.secrets["snowflake"]
    return sf.connect(
        user=s["user"], password=s["password"], account=s["account"],
        role=s.get("role", "ACCOUNTADMIN"), warehouse="COMPUTE_WH",
        database="SEOUL_DISTRICTLEVEL_DATA_FLOATING_POPULATION_CONSUMPTION_AND_ASSETS",
        schema="GRANDATA", ocsp_fail_open=True, insecure_mode=True
    )

def run_sql(sql: str) -> pd.DataFrame:
    with get_conn().cursor() as cur:
        cur.execute(sql)
        return pd.DataFrame(cur.fetchall(), columns=[c[0] for c in cur.description])

# â”€â”€ ì¿¼ë¦¬ (í–‰ ìˆ˜ ì œí•œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LIMIT = 50_000          # Snowflake ìª½ì—ì„œ ë¨¼ì € ì¤„ì„
BASE  = "SEOUL_DISTRICTLEVEL_DATA_FLOATING_POPULATION_CONSUMPTION_AND_ASSETS.GRANDATA"
SQL   = {
    "fp"   : f"SELECT * FROM {BASE}.FLOATING_POPULATION_INFO LIMIT {LIMIT}",
    "card" : f"SELECT * FROM {BASE}.CARD_SALES_INFO           LIMIT {LIMIT}",
    "asset": f"SELECT * FROM {BASE}.ASSET_INCOME_INFO         LIMIT {LIMIT}",
    "scco" : f"SELECT * FROM {BASE}.M_SCCO_MST"
}

# â”€â”€ ì „ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=True)
def preprocess() -> pd.DataFrame:
    with st.spinner("ğŸ”„ Snowflakeì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
        fp, card, asset, scco = (run_sql(SQL["fp"]), run_sql(SQL["card"]),
                                 run_sql(SQL["asset"]), run_sql(SQL["scco"]))

    # join í›„ 1 % ìƒ˜í”Œ
    data = (fp
            .merge(card , how="left", on=["STANDARD_YEAR_MONTH","DISTRICT_CODE","AGE_GROUP",
                                          "GENDER","TIME_SLOT","WEEKDAY_WEEKEND"])
            .merge(asset, how="left", on=["STANDARD_YEAR_MONTH","DISTRICT_CODE",
                                          "AGE_GROUP","GENDER"])
            .sample(frac=0.01, random_state=42))            # â† 1 % ì¶”ì¶œ

    data["DISTRICT_KOR_NAME"] = data["DISTRICT_CODE"].map(
        scco.drop_duplicates("DISTRICT_CODE")
            .set_index("DISTRICT_CODE")["DISTRICT_KOR_NAME"]
    )

    # â”€ íŒŒìƒ ë³€ìˆ˜
    data["ì „ì²´ì¸êµ¬"] = data[["RESIDENTIAL_POPULATION","WORKING_POPULATION",
                             "VISITING_POPULATION"]].sum(axis=1)

    sales_cols = ["FOOD_SALES","COFFEE_SALES","BEAUTY_SALES","ENTERTAINMENT_SALES",
                  "SPORTS_CULTURE_LEISURE_SALES","TRAVEL_SALES","CLOTHING_ACCESSORIES_SALES"]
    data["ì—”í„°ì „ì²´ë§¤ì¶œ"] = data[sales_cols].sum(axis=1)
    data["ì†Œë¹„í™œë ¥ì§€ìˆ˜"] = data["ì—”í„°ì „ì²´ë§¤ì¶œ"] / data["ì „ì²´ì¸êµ¬"].replace(0, np.nan)
    data["ìœ ì…ì§€ìˆ˜"]    = data["VISITING_POPULATION"] / (
        data["RESIDENTIAL_POPULATION"] + data["WORKING_POPULATION"]).replace(0, np.nan)
    data["ì—”í„°ë§¤ì¶œë¹„ìœ¨"] = data["ì—”í„°ì „ì²´ë§¤ì¶œ"] / data["TOTAL_SALES"].replace(0, np.nan)

    cnt_cols = ["FOOD_COUNT","COFFEE_COUNT","BEAUTY_COUNT","ENTERTAINMENT_COUNT",
                "SPORTS_CULTURE_LEISURE_COUNT","TRAVEL_COUNT","CLOTHING_ACCESSORIES_COUNT"]
    data["ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"] = data[cnt_cols].sum(axis=1)
    data["ì—”í„°ë°©ë¬¸ìë¹„ìœ¨"] = data["ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"] / data["TOTAL_COUNT"].replace(0, np.nan)
    data["ì—”í„°í™œë™ë°€ë„"]  = data["ì—”í„°ì „ì²´ë§¤ì¶œ"] / data["ì „ì²´ì¸êµ¬"].replace(0, np.nan)
    data["ì—”í„°ë§¤ì¶œë°€ë„"]  = data["ì—”í„°ì „ì²´ë§¤ì¶œ"] / data["ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"].replace(0, np.nan)

    # â”€ FEEL_IDX
    emo_vars = ["ì—”í„°ì „ì²´ë§¤ì¶œ","ì†Œë¹„í™œë ¥ì§€ìˆ˜","ìœ ì…ì§€ìˆ˜","ì—”í„°ë§¤ì¶œë¹„ìœ¨",
                "ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜","ì—”í„°ë°©ë¬¸ìë¹„ìœ¨",
                "ì—”í„°í™œë™ë°€ë„","ì—”í„°ë§¤ì¶œë°€ë„"]
    data["FEEL_IDX"] = np.nan
    X = (data[emo_vars].apply(pd.to_numeric, errors="coerce")
                     .replace([np.inf,-np.inf], np.nan).dropna())
    if not X.empty:
        pc1 = PCA(n_components=1).fit_transform(
            StandardScaler().fit_transform(X))
        data.loc[X.index, "FEEL_IDX"] = (
            (pc1 - pc1.min()) / (pc1.max() - pc1.min() + 1e-9)
        )
    return data

data = preprocess()
st.title("ì„œìš¸ì‹œ ì¸ìŠ¤íƒ€ ê°ì„± ì§€ìˆ˜ ë¶„ì„")

if data.empty:
    st.error("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. LIMIT/ìƒ˜í”Œ ë¹„ìœ¨ì„ ë†’ì—¬ ë³´ì„¸ìš”.")
    st.stop()

# â”€â”€ ì‚¬ì´ë“œë°” í•„í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    districts = st.multiselect("í–‰ì •ë™", sorted(data["DISTRICT_KOR_NAME"].dropna().unique()), [])
    ages      = st.multiselect("ì—°ë ¹ëŒ€",  sorted(data["AGE_GROUP"].unique()), [])
    gender    = st.multiselect("ì„±ë³„", ["M","F"], [])

mask = pd.Series(True, index=data.index)
if districts: mask &= data["DISTRICT_KOR_NAME"].isin(districts)
if ages:      mask &= data["AGE_GROUP"].isin(ages)
if gender:    mask &= data["GENDER"].isin(gender)

view = data[mask]

if view.empty:
    st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ ë³´ì„¸ìš”!")
    st.stop()

# â”€â”€ ìš”ì•½ ì§€í‘œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
c1,c2,c3 = st.columns(3)
c1.metric("í‰ê·  FEEL_IDX",     f"{view['FEEL_IDX'].mean():.2f}")
c2.metric("í‰ê·  ì†Œë¹„í™œë ¥ì§€ìˆ˜", f"{view['ì†Œë¹„í™œë ¥ì§€ìˆ˜'].mean():.2f}")
c3.metric("í‰ê·  ìœ ì…ì§€ìˆ˜",     f"{view['ìœ ì…ì§€ìˆ˜'].mean():.2f}")

tab1,tab2,tab3 = st.tabs(["ì§€ìˆ˜ ìƒìœ„ ì§€ì—­","ì„±ë³„Â·ì—°ë ¹ ë¶„ì„","ì‚°ì ë„"])

with tab1:
    top = view.groupby("DISTRICT_KOR_NAME")["ì†Œë¹„í™œë ¥ì§€ìˆ˜"].mean().nlargest(20)
    if top.empty:
        st.info("ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        fig, ax = plt.subplots(figsize=(10,5))
        sns.barplot(x=top.index, y=top.values, palette="rocket", ax=ax)
        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha="right")
        st.pyplot(fig)

with tab2:
    agg = view.groupby(["AGE_GROUP","GENDER"])["TOTAL_SALES"].mean().reset_index()
    if agg.empty:
        st.info("ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        fig, ax = plt.subplots(figsize=(8,4))
        sns.barplot(data=agg, x="AGE_GROUP", y="TOTAL_SALES",
                    hue="GENDER", palette={"M":"#3498db","F":"#e75480"}, ax=ax)
        st.pyplot(fig)

with tab3:
    xx = st.selectbox("Xë³€ìˆ˜", ["ì—”í„°ì „ì²´ë§¤ì¶œ","ì†Œë¹„í™œë ¥ì§€ìˆ˜","ìœ ì…ì§€ìˆ˜","ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"])
    yy = st.selectbox("Yë³€ìˆ˜", ["FEEL_IDX","ì—”í„°í™œë™ë°€ë„","ì—”í„°ë§¤ì¶œë¹„ìœ¨"])
    if view[[xx,yy]].dropna().empty:
        st.info("ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        fig, ax = plt.subplots(figsize=(6,4))
        sns.scatterplot(data=view, x=xx, y=yy,
                        hue="FEEL_IDX", palette="viridis", alpha=0.6, ax=ax)
        st.pyplot(fig)

st.divider(); st.caption("ë°ì´í„° ì¶œì²˜ Â· Snowflake Marketplace")
