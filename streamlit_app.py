###############################################################################
# streamlit_app.py â€• ì„œìš¸ì‹œ ì¸ìŠ¤íƒ€ ê°ì„± ì§€ìˆ˜ ëŒ€ì‹œë³´ë“œ
###############################################################################
import os, sys, warnings
import streamlit as st
import snowflake.connector as sf
import pandas as pd, numpy as np
import matplotlib.pyplot as plt, seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ë³¸ í™˜ê²½ ì„¸íŒ… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
os.environ["STREAMLIT_SERVER_HEALTH_CHECK_ENABLED"] = "false"   # Cloud health-check ì—ëŸ¬ ë°©ì§€
st.set_page_config(page_title="ì„œìš¸ì‹œ ê°ì„± ì§€ìˆ˜ ëŒ€ì‹œë³´ë“œ", layout="wide")
sns.set_style("whitegrid")

# â‘  í•œê¸€ í°íŠ¸ (ìœˆë„ìš°: Malgun Gothic, mac/Linux: AppleGothic fallback)
import matplotlib
if sys.platform.startswith("win"):
    matplotlib.rcParams["font.family"] = "Malgun Gothic"
else:
    matplotlib.rcParams["font.family"] = "AppleGothic"
matplotlib.rcParams["axes.unicode_minus"] = False
st.markdown('<style>*{font-family:"Malgun Gothic",sans-serif!important;}</style>',
            unsafe_allow_html=True)

st.write("ğŸš€ **Streamlit ì•± ì‹œì‘!**")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Snowflake ì—°ê²°  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_conn():
    s = st.secrets["snowflake"]             #  secrets.toml  â”€â”€>
    # [snowflake]
    # user = "..."
    # password = "..."
    # account = "TGLBRLT-EKB57194"   â† Account Identifier
    # (í•„ìš”í•˜ë©´ role / database / schema â€¦ ì¶”ê°€)
    return sf.connect(
        user      = s["user"],
        password  = s["password"],
        account   = s["account"],
        warehouse = "COMPUTE_WH",
        ocsp_fail_open = True,
        insecure_mode  = True
    )

@st.cache_data(show_spinner=False)
def load(q:str) -> pd.DataFrame:
    with get_conn() as conn:
        cur = conn.cursor()
        cur.execute(q)
        df  = pd.DataFrame(cur.fetchall(), columns=[c[0] for c in cur.description])
        cur.close()
    return df

BASE = "SEOUL_DISTRICTLEVEL_DATA_FLOATING_POPULATION_CONSUMPTION_AND_ASSETS.GRANDATA"
Q_FP    = f"SELECT * FROM {BASE}.FLOATING_POPULATION_INFO"      # 6 ë°±ë§Œ+
Q_CARD  = f"SELECT * FROM {BASE}.CARD_SALES_INFO"
Q_ASSET = f"SELECT * FROM {BASE}.ASSET_INCOME_INFO"
Q_SCCO  = f"SELECT * FROM {BASE}.M_SCCO_MST"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ì „ì²˜ë¦¬  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=True)
def preprocess() -> pd.DataFrame:

    # â‘  ë°ì´í„° ë¡œë“œ
    fp, card, asset, scco = load(Q_FP), load(Q_CARD), load(Q_ASSET), load(Q_SCCO)

    # â‘¡ ìœ ë™-ì¸êµ¬ í…Œì´ë¸”ë§Œ 1 % ìƒ˜í”Œë§í•´ ì†ë„ í™•ë³´
    fp = fp.sample(frac=0.01, random_state=42)

    # â‘¢ ì¡°ì¸ (INNER â†’ ë°ì´í„° ì •í•©)
    fp_card = pd.merge(
        fp, card, how="inner",
        on=["STANDARD_YEAR_MONTH","DISTRICT_CODE","AGE_GROUP","GENDER","TIME_SLOT","WEEKDAY_WEEKEND"]
    )
    data = pd.merge(
        fp_card, asset, how="inner",
        on=["STANDARD_YEAR_MONTH","DISTRICT_CODE","AGE_GROUP","GENDER"]
    )

    # â‘£ í–‰ì •ë™ í•œê¸€ëª… ë¶™ì´ê¸°
    scco_map = (
        scco.drop_duplicates("DISTRICT_CODE")
            .set_index("DISTRICT_CODE")["DISTRICT_KOR_NAME"].to_dict()
    )
    data["DISTRICT_KOR_NAME"] = data["DISTRICT_CODE"].map(scco_map)

    # â‘¤ íŒŒìƒ ë³€ìˆ˜
    data["ì „ì²´ì¸êµ¬"]       = data[["RESIDENTIAL_POPULATION","WORKING_POPULATION","VISITING_POPULATION"]].sum(axis=1)

    sales_cols = ["FOOD_SALES","COFFEE_SALES","BEAUTY_SALES",
                  "ENTERTAINMENT_SALES","SPORTS_CULTURE_LEISURE_SALES",
                  "TRAVEL_SALES","CLOTHING_ACCESSORIES_SALES"]
    data["ì—”í„°ì „ì²´ë§¤ì¶œ"]   = data[sales_cols].sum(axis=1)

    data["ì†Œë¹„í™œë ¥ì§€ìˆ˜"]   = data["ì—”í„°ì „ì²´ë§¤ì¶œ"] / data["ì „ì²´ì¸êµ¬"].replace(0,np.nan)
    data["ìœ ì…ì§€ìˆ˜"]       = data["VISITING_POPULATION"] / (
                              data["RESIDENTIAL_POPULATION"] + data["WORKING_POPULATION"]).replace(0,np.nan)
    data["ì—”í„°ë§¤ì¶œë¹„ìœ¨"]   = data["ì—”í„°ì „ì²´ë§¤ì¶œ"] / data["TOTAL_SALES"].replace(0,np.nan)

    cnt_cols = ["FOOD_COUNT","COFFEE_COUNT","BEAUTY_COUNT",
                "ENTERTAINMENT_COUNT","SPORTS_CULTURE_LEISURE_COUNT",
                "TRAVEL_COUNT","CLOTHING_ACCESSORIES_COUNT"]
    data["ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"] = data[cnt_cols].sum(axis=1)
    data["ì—”í„°ë°©ë¬¸ìë¹„ìœ¨"] = data["ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"] / data["TOTAL_COUNT"].replace(0,np.nan)
    data["ì—”í„°í™œë™ë°€ë„"]   = data["ì—”í„°ì „ì²´ë§¤ì¶œ"] / data["ì „ì²´ì¸êµ¬"].replace(0,np.nan)
    data["ì—”í„°ë§¤ì¶œë°€ë„"]   = data["ì—”í„°ì „ì²´ë§¤ì¶œ"] / data["ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"].replace(0,np.nan)

    # â‘¥ FEEL_IDX (PCA 1-ì£¼ì„±ë¶„) â€” ë°°ì—´ â†’ float ë¡œ í‰íƒ„í™”
    emo_vars = ["ì—”í„°ì „ì²´ë§¤ì¶œ","ìœ ì…ì§€ìˆ˜","ì—”í„°ë§¤ì¶œë¹„ìœ¨",
                "ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜","ì—”í„°ë°©ë¬¸ìë¹„ìœ¨","ì—”í„°í™œë™ë°€ë„","ì—”í„°ë§¤ì¶œë°€ë„"]
    data["FEEL_IDX"] = np.nan
    X = data[emo_vars].apply(pd.to_numeric, errors="coerce").dropna()
    if not X.empty:
        X_std = StandardScaler().fit_transform(X)
        pc1   = PCA(n_components=1).fit_transform(X_std).ravel()      # â† ravelë¡œ 1-D
        pc1_n = (pc1 - pc1.min())/(pc1.max() - pc1.min() + 1e-9)
        data.loc[X.index, "FEEL_IDX"] = pc1_n.astype(float)           # â† float ì»¬ëŸ¼

    return data

df_base = preprocess()
st.title("ì„œìš¸ì‹œ ì¸ìŠ¤íƒ€ ê°ì„± ì§€ìˆ˜ ë¶„ì„")

if df_base.empty:
    st.error("âŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ìƒ˜í”Œë§ ë¹„ìœ¨ì„ ë†’ì—¬ ë³´ì„¸ìš”)")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ì‚¬ì´ë“œë°” í•„í„°  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("í•„í„°")
    sel_dist = st.multiselect("í–‰ì •ë™", sorted(df_base["DISTRICT_KOR_NAME"].dropna().unique()))
    sel_age  = st.multiselect("ì—°ë ¹ëŒ€",  sorted(df_base["AGE_GROUP"].unique()))
    sel_gen  = st.multiselect("ì„±ë³„",     ["M","F"])

mask = (
    (df_base["DISTRICT_KOR_NAME"].isin(sel_dist) if sel_dist else True) &
    (df_base["AGE_GROUP"].isin(sel_age)           if sel_age  else True) &
    (df_base["GENDER"].isin(sel_gen)              if sel_gen  else True)
)
view = df_base.loc[mask]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ìš”ì•½ ì§€í‘œ  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if view.empty:
    st.warning("â—»ï¸ ì„ íƒëœ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” í–‰ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

c1,c2,c3 = st.columns(3)
c1.metric("í‰ê·  FEEL_IDX",     f"{view['FEEL_IDX'].mean():.3f}")
c2.metric("í‰ê·  ì†Œë¹„í™œë ¥ì§€ìˆ˜", f"{view['ì†Œë¹„í™œë ¥ì§€ìˆ˜'].mean():.3f}")
c3.metric("í‰ê·  ìœ ì…ì§€ìˆ˜",     f"{view['ìœ ì…ì§€ìˆ˜'].mean():.3f}")

tab1,tab2,tab3 = st.tabs(["ì§€ìˆ˜ ìƒìœ„ ì§€ì—­","ì„±ë³„Â·ì—°ë ¹ ë¶„ì„","ì‚°ì ë„"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  íƒ­ 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab1:
    top = (view.groupby("DISTRICT_KOR_NAME")["ì†Œë¹„í™œë ¥ì§€ìˆ˜"]
                 .mean().sort_values(ascending=False).head(20))
    if top.empty:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        fig, ax = plt.subplots(figsize=(10,4))
        sns.barplot(x=top.index, y=top.values, palette="rocket", ax=ax)
        ax.set_xlabel("í–‰ì •ë™"); ax.set_ylabel("ì†Œë¹„í™œë ¥ì§€ìˆ˜")
        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha="right")
        st.pyplot(fig)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  íƒ­ 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab2:
    agg = (view.groupby(["AGE_GROUP","GENDER"])["TOTAL_SALES"]
                 .mean().reset_index())
    if agg.empty:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        fig, ax = plt.subplots(figsize=(8,4))
        sns.barplot(data=agg, x="AGE_GROUP", y="TOTAL_SALES",
                    hue="GENDER", palette={"M":"#3498db","F":"#e75480"}, ax=ax)
        ax.set_ylabel("1ì¼ í‰ê·  ë§¤ì¶œ")
        st.pyplot(fig)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  íƒ­ 3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab3:
    base = view.dropna(subset=["FEEL_IDX"])
    if base.empty:
        st.info("FEEL_IDX ê°€ ì—†ëŠ” í–‰ì…ë‹ˆë‹¤.")
    else:
        xx = st.selectbox("X ë³€ìˆ˜", ["ì—”í„°ì „ì²´ë§¤ì¶œ","ì†Œë¹„í™œë ¥ì§€ìˆ˜","ìœ ì…ì§€ìˆ˜","ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"])
        yy = st.selectbox("Y ë³€ìˆ˜", ["FEEL_IDX","ì—”í„°í™œë™ë°€ë„","ì—”í„°ë§¤ì¶œë¹„ìœ¨"])
        fig, ax = plt.subplots(figsize=(6,4))
        sns.scatterplot(data=base, x=xx, y=yy, hue="FEEL_IDX",
                        palette="viridis", alpha=0.5, ax=ax)
        st.pyplot(fig)

st.divider()
st.caption("ë°ì´í„° ì¶œì²˜ Â· Snowflake Marketplace")
