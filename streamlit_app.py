# streamlit_app.py
import os, urllib.request, streamlit as st, snowflake.connector as sf
import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from matplotlib import font_manager

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0. UI & í•œê¸€ í°íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
os.environ["STREAMLIT_SERVER_HEALTH_CHECK_ENABLED"] = "false"
st.set_page_config(page_title="ì„œìš¸ì‹œ ê°ì„± ì§€ìˆ˜ ëŒ€ì‹œë³´ë“œ", layout="wide")
sns.set_style("whitegrid")

# â–¶â€†Google Fonts ë‹¤ìš´ë¡œë“œ â†’ Matplotlib + Streamlit ì ìš©
FONT_URL  = ("https://github.com/googlefonts/noto-cjk/raw/main/"
             "Sans/OTF/Korean/NotoSansCJKkr-Regular.otf")
FONT_PATH = "/tmp/NotoSansKR.otf"
if not os.path.exists(FONT_PATH):
    urllib.request.urlretrieve(FONT_URL, FONT_PATH)
    font_manager.fontManager.addfont(FONT_PATH)
plt.rcParams["font.family"] = "Noto Sans CJK KR"
plt.rcParams["axes.unicode_minus"] = False

st.markdown("""
<style>
@font-face { font-family: "Noto Sans KR"; src: url("https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;700&display=swap"); }
* { font-family: "Noto Sans KR", sans-serif !important; }
</style>
""", unsafe_allow_html=True)

st.write("ğŸš€ **Streamlit ì•± ì‹œì‘!**")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. Snowflake ì—°ê²° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner=False)
def get_conn():
    s = st.secrets["snowflake"]
    return sf.connect(
        user=s["user"], password=s["password"], account=s["account"],
        role=s.get("role", "ACCOUNTADMIN"), warehouse="COMPUTE_WH",
        database="SEOUL_DISTRICTLEVEL_DATA_FLOATING_POPULATION_CONSUMPTION_AND_ASSETS",
        schema="GRANDATA", ocsp_fail_open=True, insecure_mode=True
    )

def run_sql(sql: str) -> pd.DataFrame:
    with get_conn().cursor() as cur:
        cur.execute(sql)
        return pd.DataFrame(cur.fetchall(), columns=[c[0] for c in cur.description])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. ë°ì´í„° ë¡œë“œ & ì „ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LIMIT = 50_000   # â†’ 1% ìƒ˜í”Œ ì§ì „, Snowflake ì¿¼ë¦¬ ìì²´ë¥¼ ê¸°Â·ë³¸Â·ì Â·ìœ¼Â·ë¡œ ì œí•œ
BASE  = "SEOUL_DISTRICTLEVEL_DATA_FLOATING_POPULATION_CONSUMPTION_AND_ASSETS.GRANDATA"
SQL   = {t: f"SELECT * FROM {BASE}.{tbl} LIMIT {LIMIT}" for t, tbl in {
            "fp"   : "FLOATING_POPULATION_INFO",
            "card" : "CARD_SALES_INFO",
            "asset": "ASSET_INCOME_INFO",
            "scco" : "M_SCCO_MST"}.items()}

@st.cache_data(show_spinner=True)
def preprocess() -> pd.DataFrame:
    fp, card, asset, scco = (run_sql(SQL["fp"]), run_sql(SQL["card"]),
                             run_sql(SQL["asset"]), run_sql(SQL["scco"]))

    df = (fp
          .merge(card , how="left", on=["STANDARD_YEAR_MONTH","DISTRICT_CODE",
                                        "AGE_GROUP","GENDER","TIME_SLOT","WEEKDAY_WEEKEND"])
          .merge(asset, how="left", on=["STANDARD_YEAR_MONTH","DISTRICT_CODE",
                                        "AGE_GROUP","GENDER"])
          .sample(frac=0.01, random_state=42))                      # 1 % ì¶”ì¶œ

    df["DISTRICT_KOR_NAME"] = df["DISTRICT_CODE"].map(
        scco.drop_duplicates("DISTRICT_CODE")
            .set_index("DISTRICT_CODE")["DISTRICT_KOR_NAME"]
    )

    # â–¶ ìˆ«ì ì—´ ì „ì²´ ì‹¤ìˆ˜í˜• ë³€í™˜
    num_cols = df.select_dtypes(include="object").columns.difference(
        ["STANDARD_YEAR_MONTH","DISTRICT_CODE","AGE_GROUP","GENDER",
         "TIME_SLOT","WEEKDAY_WEEKEND","DISTRICT_KOR_NAME"])
    df[num_cols] = df[num_cols].apply(pd.to_numeric, errors="coerce")

    # â”€ íŒŒìƒ ë³€ìˆ˜ ê³„ì‚°
    df["ì „ì²´ì¸êµ¬"] = df[["RESIDENTIAL_POPULATION","WORKING_POPULATION",
                         "VISITING_POPULATION"]].sum(axis=1)

    sales_cols = ["FOOD_SALES","COFFEE_SALES","BEAUTY_SALES","ENTERTAINMENT_SALES",
                  "SPORTS_CULTURE_LEISURE_SALES","TRAVEL_SALES",
                  "CLOTHING_ACCESSORIES_SALES"]
    df["ì—”í„°ì „ì²´ë§¤ì¶œ"] = df[sales_cols].sum(axis=1)
    df["ì†Œë¹„í™œë ¥ì§€ìˆ˜"] = df["ì—”í„°ì „ì²´ë§¤ì¶œ"] / df["ì „ì²´ì¸êµ¬"].replace(0, np.nan)
    df["ìœ ì…ì§€ìˆ˜"]    = df["VISITING_POPULATION"] / (
        df["RESIDENTIAL_POPULATION"] + df["WORKING_POPULATION"]).replace(0, np.nan)
    df["ì—”í„°ë§¤ì¶œë¹„ìœ¨"] = df["ì—”í„°ì „ì²´ë§¤ì¶œ"] / df["TOTAL_SALES"].replace(0, np.nan)

    cnt_cols = ["FOOD_COUNT","COFFEE_COUNT","BEAUTY_COUNT","ENTERTAINMENT_COUNT",
                "SPORTS_CULTURE_LEISURE_COUNT","TRAVEL_COUNT","CLOTHING_ACCESSORIES_COUNT"]
    df["ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"] = df[cnt_cols].sum(axis=1)
    df["ì—”í„°ë°©ë¬¸ìë¹„ìœ¨"] = df["ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"] / df["TOTAL_COUNT"].replace(0, np.nan)
    df["ì—”í„°í™œë™ë°€ë„"]  = df["ì—”í„°ì „ì²´ë§¤ì¶œ"] / df["ì „ì²´ì¸êµ¬"].replace(0, np.nan)
    df["ì—”í„°ë§¤ì¶œë°€ë„"]  = df["ì—”í„°ì „ì²´ë§¤ì¶œ"] / df["ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"].replace(0, np.nan)

    # â”€ FEEL_IDX (PCA 1-ì¶•)
    emo_vars = ["ì—”í„°ì „ì²´ë§¤ì¶œ","ì†Œë¹„í™œë ¥ì§€ìˆ˜","ìœ ì…ì§€ìˆ˜","ì—”í„°ë§¤ì¶œë¹„ìœ¨",
                "ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜","ì—”í„°ë°©ë¬¸ìë¹„ìœ¨","ì—”í„°í™œë™ë°€ë„","ì—”í„°ë§¤ì¶œë°€ë„"]
    df["FEEL_IDX"] = np.nan
    X = df[emo_vars].dropna()
    if not X.empty:
        pc1 = PCA(1).fit_transform(StandardScaler().fit_transform(X))
        df.loc[X.index, "FEEL_IDX"] = (pc1 - pc1.min())/(pc1.max()-pc1.min()+1e-9)

    return df

data = preprocess()
st.title("ì„œìš¸ì‹œ ì¸ìŠ¤íƒ€ ê°ì„± ì§€ìˆ˜ ë¶„ì„")

if data.empty:
    st.error("Snowflakeì—ì„œ ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ - LIMIT ê°’ì„ ëŠ˜ë ¤ ë³´ì„¸ìš”.")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. ì‚¬ì´ë“œë°” í•„í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    districts = st.multiselect("í–‰ì •ë™", sorted(data["DISTRICT_KOR_NAME"].dropna().unique()))
    ages      = st.multiselect("ì—°ë ¹ëŒ€",  sorted(data["AGE_GROUP"].unique()))
    gender    = st.multiselect("ì„±ë³„", ["M","F"])

mask = pd.Series(True, index=data.index)
if districts: mask &= data["DISTRICT_KOR_NAME"].isin(districts)
if ages:      mask &= data["AGE_GROUP"].isin(ages)
if gender:    mask &= data["GENDER"].isin(gender)

view = data[mask]
if view.empty:
    st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ ë³´ì„¸ìš”!")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. ìš”ì•½ ì§€í‘œ & ê·¸ë˜í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
c1,c2,c3 = st.columns(3)
c1.metric("í‰ê·  FEEL_IDX",     f"{view['FEEL_IDX'].mean():.2f}")
c2.metric("í‰ê·  ì†Œë¹„í™œë ¥ì§€ìˆ˜", f"{view['ì†Œë¹„í™œë ¥ì§€ìˆ˜'].mean():.2f}")
c3.metric("í‰ê·  ìœ ì…ì§€ìˆ˜",     f"{view['ìœ ì…ì§€ìˆ˜'].mean():.2f}")

tab1,tab2,tab3 = st.tabs(["ì§€ìˆ˜ ìƒìœ„ ì§€ì—­","ì„±ë³„Â·ì—°ë ¹ ë¶„ì„","ì‚°ì ë„"])

with tab1:
    top = view.groupby("DISTRICT_KOR_NAME")["ì†Œë¹„í™œë ¥ì§€ìˆ˜"].mean().nlargest(20)
    if top.empty:
        st.info("ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        fig, ax = plt.subplots(figsize=(10,5))
        sns.barplot(x=top.index, y=top.values, palette="rocket", ax=ax)
        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha="right")
        st.pyplot(fig)

with tab2:
    agg = view.groupby(["AGE_GROUP","GENDER"])["TOTAL_SALES"].mean().reset_index()
    if agg.empty:
        st.info("ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        fig, ax = plt.subplots(figsize=(8,4))
        sns.barplot(data=agg, x="AGE_GROUP", y="TOTAL_SALES",
                    hue="GENDER", palette={"M":"#3498db","F":"#e75480"}, ax=ax)
        st.pyplot(fig)

with tab3:
    xx = st.selectbox("Xë³€ìˆ˜", ["ì—”í„°ì „ì²´ë§¤ì¶œ","ì†Œë¹„í™œë ¥ì§€ìˆ˜","ìœ ì…ì§€ìˆ˜","ì—”í„°ì „ì²´ë°©ë¬¸ììˆ˜"])
    yy = st.selectbox("Yë³€ìˆ˜", ["FEEL_IDX","ì—”í„°í™œë™ë°€ë„","ì—”í„°ë§¤ì¶œë¹„ìœ¨"])
    if view[[xx,yy]].dropna().empty:
        st.info("ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        fig, ax = plt.subplots(figsize=(6,4))
        sns.scatterplot(data=view, x=xx, y=yy,
                        hue="FEEL_IDX", palette="viridis", alpha=0.6, ax=ax)
        st.pyplot(fig)

st.divider(); st.caption("ë°ì´í„° ì¶œì²˜ Â· Snowflake Marketplace")
